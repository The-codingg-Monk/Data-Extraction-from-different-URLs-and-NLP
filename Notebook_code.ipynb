{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d94ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import requests\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import re\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4919967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(r\"input.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e8213d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<head><title>Not Acceptable!</title></head><body><h1>Not Acceptable!</h1><p>An appropriate representation of the requested resource could not be found on this server. This error was generated by Mod_Security.</p></body></html>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/'\n",
    "\n",
    "data=requests.get(url)\n",
    "data.text  #Access has been prohibited so instead of beatuful soup we will use scrapy.\n",
    "\n",
    "#Web scrapping using scrapy has been done on vs code, have shared code in vs code folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d76b40a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url_id</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“If anything kills over 10 million people in t...</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes</td>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where is this disruptive technology taking us?...</td>\n",
       "      <td>Will machine replace the human in the future o...</td>\n",
       "      <td>42</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human minds, a fascination in itself carrying ...</td>\n",
       "      <td>What if the Creation is Taking Over the Creator?</td>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“Anything that could give rise to smarter-than...</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Machine intelligence is the last invention th...</td>\n",
       "      <td>Will AI Replace Us or Work With Us?</td>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  “If anything kills over 10 million people in t...   \n",
       "1  Where is this disruptive technology taking us?...   \n",
       "2  Human minds, a fascination in itself carrying ...   \n",
       "3  “Anything that could give rise to smarter-than...   \n",
       "4  “Machine intelligence is the last invention th...   \n",
       "\n",
       "                                               title  url_id  \\\n",
       "0       AI in healthcare to Improve Patient Outcomes      37   \n",
       "1  Will machine replace the human in the future o...      42   \n",
       "2   What if the Creation is Taking Over the Creator?      38   \n",
       "3  Will Machine Replace The Human in the Future o...      40   \n",
       "4                Will AI Replace Us or Work With Us?      41   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://insights.blackcoffer.com/ai-in-healthc...  \n",
       "1  https://insights.blackcoffer.com/what-if-the-c...  \n",
       "2  https://insights.blackcoffer.com/what-jobs-wil...  \n",
       "3  https://insights.blackcoffer.com/will-machine-...  \n",
       "4  https://insights.blackcoffer.com/will-ai-repla...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_df=pd.read_csv(r'C:\\Users\\kannu\\OneDrive\\Desktop\\DataScience\\Projects\\Blackcoffer\\20211030 Test Assignment\\vscode\\scraping_text\\scraping_text\\Extracted_data.csv')\n",
    "extracted_df[\"URL\"]=df[\"URL\"]\n",
    "extracted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c971f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>url_id</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“If anything kills over 10 million people in t...</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes</td>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where is this disruptive technology taking us?...</td>\n",
       "      <td>Will machine replace the human in the future o...</td>\n",
       "      <td>42</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Human minds, a fascination in itself carrying ...</td>\n",
       "      <td>What if the Creation is Taking Over the Creator?</td>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“Anything that could give rise to smarter-than...</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“Machine intelligence is the last invention th...</td>\n",
       "      <td>Will AI Replace Us or Work With Us?</td>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  “If anything kills over 10 million people in t...   \n",
       "1  Where is this disruptive technology taking us?...   \n",
       "2  Human minds, a fascination in itself carrying ...   \n",
       "3  “Anything that could give rise to smarter-than...   \n",
       "4  “Machine intelligence is the last invention th...   \n",
       "\n",
       "                                               title  url_id  \\\n",
       "0       AI in healthcare to Improve Patient Outcomes      37   \n",
       "1  Will machine replace the human in the future o...      42   \n",
       "2   What if the Creation is Taking Over the Creator?      38   \n",
       "3  Will Machine Replace The Human in the Future o...      40   \n",
       "4                Will AI Replace Us or Work With Us?      41   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://insights.blackcoffer.com/ai-in-healthc...  \n",
       "1  https://insights.blackcoffer.com/what-if-the-c...  \n",
       "2  https://insights.blackcoffer.com/what-jobs-wil...  \n",
       "3  https://insights.blackcoffer.com/will-machine-...  \n",
       "4  https://insights.blackcoffer.com/will-ai-repla...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removind special characters from text data,so that can be stored in txt file.\n",
    "\n",
    "\n",
    "def rm_char(data):\n",
    "    \n",
    "    res=re.sub(\"\\u20b9\",\"\",data)\n",
    "    return res\n",
    "\n",
    "extracted_df[\"text\"]= extracted_df[\"text\"].apply(rm_char)\n",
    "extracted_df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93384686",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"Gathered_texts\")\n",
    "os.mkdir('Gathered_texts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3148529f",
   "metadata": {},
   "source": [
    "## Putting all stopwords in a single place, inside a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e15de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting all stopwords in a single place inside list.\n",
    "\n",
    "stop_word_paths=glob.glob('StopWords\\*.txt')     #getting stopwords paths\n",
    "for path in stop_word_paths:\n",
    "    with open(path,'r') as file:\n",
    "        data=file.read()\n",
    "        with open('stop_words.txt','a') as file1:\n",
    "            file1.write(data)\n",
    "            \n",
    "with open('stop_words.txt','r') as file:\n",
    "    all_stopwords=file.read()\n",
    "\n",
    "cleaned=re.sub(\"\\W+\",\" \",all_stopwords).lower()\n",
    "stopwords_list=[word.lower() for word in re.sub(\"\\d+\",\"\",cleaned).split() if word not in punctuation]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8629a9",
   "metadata": {},
   "source": [
    "## Preprocessing negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88e57024",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"MasterDictionary/negative-words.txt\") as file:\n",
    "    negative_data=file.read()\n",
    "    \n",
    "cleaned=re.sub(\"\\W+\",\" \",negative_data)\n",
    "cleaned_neg_text=[word.lower() for word in word_tokenize(re.sub(\"\\d+\",\"\",cleaned)) if (word not in punctuation) and (word.lower() not in stopwords_list)]\n",
    "\n",
    "#Performing lemmatization to convert each word into its root word.\n",
    "final_neg_words=[]\n",
    "lemma=WordNetLemmatizer()\n",
    "\n",
    "for word in cleaned_neg_text:\n",
    "    final_neg_words.append(lemma.lemmatize(word,'v'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3177c1",
   "metadata": {},
   "source": [
    "## Preprocessing positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813c8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"MasterDictionary/positive-words.txt\") as file:\n",
    "    positive_data=file.read()\n",
    "    \n",
    "cleaned=re.sub(\"\\W+\",\" \",positive_data)\n",
    "cleaned_pos_text=[word.lower() for word in word_tokenize (re.sub(\"\\d+\",\"\",cleaned)) if (word not in punctuation) and (word.lower() not in stopwords_list)]\n",
    "\n",
    "#Performing lemmatization to convert each word into its root word.\n",
    "final_pos_words=[]\n",
    "lemma=WordNetLemmatizer()\n",
    "\n",
    "for word in cleaned_pos_text:\n",
    "    final_pos_words.append(lemma.lemmatize(word,'v'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be126ff7",
   "metadata": {},
   "source": [
    "## Saving Extracted data in .txt file having name as url_id and Analysing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b42d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_no=[]\n",
    "url=[]\n",
    "pos_score=[]\n",
    "neg_score=[]\n",
    "pol_score=[]\n",
    "sub_score=[]\n",
    "avg_sent_length=[]\n",
    "p_of_complex=[]\n",
    "fog_index=[]\n",
    "avg_word_per_sent=[]\n",
    "word_counts=[]\n",
    "syllable_per_word=[]\n",
    "personal_pronounce=[]\n",
    "avg_word_length=[]\n",
    "complex_word_count_data=[]\n",
    "\n",
    "\n",
    "for text,title,url_id,link in extracted_df.values:\n",
    "    loc=str(url_id)+\".txt\"\n",
    "    with open(os.path.join('Gathered_texts',loc),'a') as file:\n",
    "        file.write(title)\n",
    "        file.write('\\n')\n",
    "        file.write(text)\n",
    "\n",
    "        \n",
    "    output_text=title+' '+text\n",
    "    \n",
    "    cleaned=re.sub(\"\\W+\",\" \",output_text)\n",
    "    word_list=[word.lower() for word in word_tokenize (re.sub(\"\\d+\",\"\",cleaned)) if (word not in punctuation) and (word.lower() not in stopwords_list)]\n",
    "    \n",
    "    final_lemmatized_words=[]\n",
    "    lemma=WordNetLemmatizer()\n",
    "\n",
    "    for word in word_list:\n",
    "        final_lemmatized_words.append(lemma.lemmatize(word,'v'))\n",
    "        \n",
    "    pos=0\n",
    "    neg=0\n",
    "     \n",
    "    for words in  final_lemmatized_words:\n",
    "        if words in final_pos_words:\n",
    "            pos+=1\n",
    "        elif words in final_neg_words:\n",
    "            neg-=1\n",
    "            \n",
    "    neg*=-1\n",
    "    \n",
    "    polarity=(pos-neg)/((pos+neg)+0.000001)\n",
    "    sub=(pos + neg)/ ((len(final_lemmatized_words)) + 0.000001)\n",
    "    \n",
    "    #Performing Sentence tokenization to find no of sentences.\n",
    "    no_of_sent=sent_tokenize(output_text)\n",
    "    \n",
    "    #Performing word tokenization to find no of words\n",
    "    data_word=re.sub('[.\")()]',\" \",output_text)\n",
    "    word_no=word_tokenize(data_word)\n",
    "    \n",
    "    avg_len=len(word_no)/len(no_of_sent)\n",
    "    \n",
    "    #Finding complex words from sentence\n",
    "    \n",
    "    complex_words=[]\n",
    "    \n",
    "    for word in word_no:\n",
    "        count=0\n",
    "        for char in word:\n",
    "            if char.lower() in [\"a\",\"e\",\"i\",\"o\",\"u\"] and not(word.endswith(\"es\"))and not(word.endswith(\"ed\")):\n",
    "                count+=1\n",
    "                \n",
    "        if count>2:\n",
    "            complex_words.append(word)\n",
    "            \n",
    "        \n",
    "    per_compl_score=len(complex_words)/len(word_no)\n",
    "    fog=(0.4*avg_len)+per_compl_score\n",
    "    avg_no_of_words_per_sent=avg_len\n",
    "    complex_words_count=len(complex_words)\n",
    "    word_count=len(final_lemmatized_words)\n",
    "    \n",
    "    count=0\n",
    "    for word in word_no:\n",
    "        for char in word:\n",
    "            if char.lower() in [\"a\",\"e\",\"i\",\"o\",\"u\"] and not(word.endswith(\"es\"))and not(word.endswith(\"ed\")):\n",
    "                count+=1\n",
    "                \n",
    "    syll_per_word=count/len(word_no)\n",
    "    personal_pronouns=0\n",
    "    \n",
    "    text='i we my ours us'\n",
    "    for word in word_tokenize(output_text):\n",
    "        \n",
    "        if word !=\"US\":\n",
    "            if word.lower() in text.split():\n",
    "                personal_pronouns +=1\n",
    "    total_char=0           \n",
    "    for word in word_no:\n",
    "        for char in word:\n",
    "            total_char+=1\n",
    "            \n",
    "    avr_word_len=total_char/len(word_no)\n",
    "            \n",
    "                \n",
    "                \n",
    "    \n",
    "    url_no.append(url_id)\n",
    "    url.append(link)\n",
    "    pos_score.append(pos)\n",
    "    neg_score.append(neg)\n",
    "    pol_score.append(polarity)\n",
    "    sub_score.append(sub)\n",
    "    avg_sent_length.append(avg_len)\n",
    "    p_of_complex.append(per_compl_score)\n",
    "    fog_index.append(fog)\n",
    "    avg_word_per_sent.append(avg_no_of_words_per_sent)\n",
    "    complex_word_count_data.append(complex_words_count)\n",
    "    word_counts.append(word_count)\n",
    "    syllable_per_word.append(syll_per_word)\n",
    "    personal_pronounce.append(personal_pronouns)\n",
    "    avg_word_length.append(avr_word_len)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67ed0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=pd.DataFrame({\"URL_ID\":url_no,\"URL\":url,\"POSITIVE SCORE\":pos_score,\"NEGATIVE SCORE\":neg_score,\"POLARITY SCORE\":pol_score,\"SUBJECTIVITY SCORE\":sub_score,\"AVG SENTENCE LENGTH\":avg_sent_length,\"PERCENTAGE OF COMPLEX WORDS\":p_of_complex,\"FOG INDEX\":fog_index,\"AVG NUMBER OF WORDS PER SENTENCE\":avg_word_per_sent,\"COMPLEX WORD COUNT\":complex_word_count_data,\"WORD COUNT\":word_counts,\"SYLLABLE PER WORD\":syllable_per_word,\"PERSONAL PRONOUNS\":personal_pronounce,\"AVG WORD LENGTH\":avg_word_length})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e7dafbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>102</td>\n",
       "      <td>54</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.165605</td>\n",
       "      <td>25.712329</td>\n",
       "      <td>0.272243</td>\n",
       "      <td>10.557174</td>\n",
       "      <td>25.712329</td>\n",
       "      <td>511</td>\n",
       "      <td>942</td>\n",
       "      <td>1.788492</td>\n",
       "      <td>1</td>\n",
       "      <td>5.353223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>67</td>\n",
       "      <td>43</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.216963</td>\n",
       "      <td>24.232143</td>\n",
       "      <td>0.187915</td>\n",
       "      <td>9.880772</td>\n",
       "      <td>24.232143</td>\n",
       "      <td>255</td>\n",
       "      <td>507</td>\n",
       "      <td>1.571113</td>\n",
       "      <td>21</td>\n",
       "      <td>4.627119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>86</td>\n",
       "      <td>57</td>\n",
       "      <td>0.202797</td>\n",
       "      <td>0.269303</td>\n",
       "      <td>19.637500</td>\n",
       "      <td>0.161044</td>\n",
       "      <td>8.016044</td>\n",
       "      <td>19.637500</td>\n",
       "      <td>253</td>\n",
       "      <td>531</td>\n",
       "      <td>1.457034</td>\n",
       "      <td>6</td>\n",
       "      <td>4.434118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>81</td>\n",
       "      <td>39</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.215827</td>\n",
       "      <td>18.269663</td>\n",
       "      <td>0.184502</td>\n",
       "      <td>7.492367</td>\n",
       "      <td>18.269663</td>\n",
       "      <td>300</td>\n",
       "      <td>556</td>\n",
       "      <td>1.635916</td>\n",
       "      <td>16</td>\n",
       "      <td>4.563961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>81</td>\n",
       "      <td>50</td>\n",
       "      <td>0.236641</td>\n",
       "      <td>0.185816</td>\n",
       "      <td>23.974026</td>\n",
       "      <td>0.194475</td>\n",
       "      <td>9.784085</td>\n",
       "      <td>23.974026</td>\n",
       "      <td>359</td>\n",
       "      <td>705</td>\n",
       "      <td>1.575840</td>\n",
       "      <td>18</td>\n",
       "      <td>4.710184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...             102   \n",
       "1      42  https://insights.blackcoffer.com/what-if-the-c...              67   \n",
       "2      38  https://insights.blackcoffer.com/what-jobs-wil...              86   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...              81   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...              81   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0              54        0.307692            0.165605            25.712329   \n",
       "1              43        0.218182            0.216963            24.232143   \n",
       "2              57        0.202797            0.269303            19.637500   \n",
       "3              39        0.350000            0.215827            18.269663   \n",
       "4              50        0.236641            0.185816            23.974026   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                     0.272243  10.557174                         25.712329   \n",
       "1                     0.187915   9.880772                         24.232143   \n",
       "2                     0.161044   8.016044                         19.637500   \n",
       "3                     0.184502   7.492367                         18.269663   \n",
       "4                     0.194475   9.784085                         23.974026   \n",
       "\n",
       "   COMPLEX WORD COUNT  WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  \\\n",
       "0                 511         942           1.788492                  1   \n",
       "1                 255         507           1.571113                 21   \n",
       "2                 253         531           1.457034                  6   \n",
       "3                 300         556           1.635916                 16   \n",
       "4                 359         705           1.575840                 18   \n",
       "\n",
       "   AVG WORD LENGTH  \n",
       "0         5.353223  \n",
       "1         4.627119  \n",
       "2         4.434118  \n",
       "3         4.563961  \n",
       "4         4.710184  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5543a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_excel(\"Result.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3792e24a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
